{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is  SQL project is done by Group_number_26 .This python codes are written in vscode Jupyter Notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Establishing the snowflakes connection  with username, password \n",
    "import snowflake.connector\n",
    "conn = snowflake.connector.connect(\n",
    "    user='smurali',\n",
    "    password='SQLproject123@',\n",
    "    account='rsb78904'\n",
    ")\n",
    "cs = conn.cursor()\n",
    "ware_house_name='warehouse1'\n",
    "Database_name='Group_26_DataBase'\n",
    "cs.execute(f\"CREATE WAREHOUSE IF NOT EXISTS {ware_house_name}\")\n",
    "cs.execute(f\"Create DATABASE IF NOT EXISTS {Database_name}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff46399e90>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the file formats (csv, xml)\n",
    "\n",
    "cs.execute(\"use Database Group_26_DataBase\")\n",
    "query_to_create_csv_format = \"\"\"\n",
    "CREATE OR REPLACE FILE FORMAT csv_format\n",
    "TYPE = 'CSV'\n",
    "FIELD_OPTIONALLY_ENCLOSED_BY = '\"'\n",
    "\"\"\"\n",
    "cs.execute(query_to_create_csv_format)\n",
    "\n",
    "# XML format\n",
    "query_to_create_xml_format = \"\"\"\n",
    "CREATE OR REPLACE FILE FORMAT xml_format\n",
    "TYPE = 'XML'\n",
    "\"\"\"\n",
    "cs.execute(query_to_create_xml_format)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract and load the 41 comma delimited purchases data files and form a single table of purchases\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema created successfully\n",
      "Stage created successfully.\n"
     ]
    }
   ],
   "source": [
    "# schema \n",
    "Database_name = 'Group_26_DataBase'\n",
    "cs.execute(f\"use DATABASE {Database_name}\") \n",
    "\n",
    "schema_name= 'purchase_order_Schema'\n",
    "try:\n",
    "    cs.execute(f\"CREATE SCHEMA IF NOT EXISTS {schema_name} \")\n",
    "    print(\"Schema created successfully\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "\n",
    "# creating a stage names \n",
    "stage_name ='purchase_order_stage'\n",
    "schema_name= 'purchase_order_Schema'\n",
    "try:\n",
    "    cs.execute(f\"CREATE OR REPLACE STAGE {schema_name}.{stage_name}\")\n",
    "    print(\"Stage created successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff46399e90>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs.execute(\n",
    "    \"\"\" \n",
    "    CREATE OR REPLACE TABLE PurchaseOrders (\n",
    "        PurchaseOrderID INT,\n",
    "        SupplierID INT,\n",
    "        OrderDate DATE,\n",
    "        DeliveryMethodID INT,\n",
    "        ContactPersonID INT,\n",
    "        ExpectedDeliveryDate DATE,\n",
    "        SupplierReference VARCHAR(255),\n",
    "        IsOrderFinalized BOOLEAN,\n",
    "        Comments VARCHAR,\n",
    "        InternalComments VARCHAR,\n",
    "        LastEditedBy INT,\n",
    "        LastEditedWhen TIMESTAMP,\n",
    "        PurchaseOrderLineID INT,\n",
    "        StockItemID INT,\n",
    "        OrderedOuters INT,\n",
    "        Description VARCHAR,\n",
    "        ReceivedOuters INT,\n",
    "        PackageTypeID INT,\n",
    "        ExpectedUnitPricePerOuter FLOAT,\n",
    "        LastReceiptDate DATE,\n",
    "        IsOrderLineFinalized BOOLEAN,\n",
    "        Right_LastEditedBy INT,\n",
    "        Right_LastEditedWhen TIMESTAMP\n",
    "    );\n",
    "    \"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for CSV files in: /home/jovyan/Desktop/testrepo/Monthlypurchaseorder\n",
      "('purchase_order_stage/2019-1.csv.gz', 6784, 'e1ddb7b6b1789c60184dc7e5b51d062a', 'Sun, 1 Sep 2024 22:44:09 GMT')\n",
      "('purchase_order_stage/2019-10.csv.gz', 3328, 'eb0320ffdb6f4178942e76e17e2be4b6', 'Sun, 1 Sep 2024 22:44:20 GMT')\n",
      "('purchase_order_stage/2019-11.csv.gz', 3056, '149fded7aceb8ea5fbfa4e32133f1d5d', 'Sun, 1 Sep 2024 22:44:20 GMT')\n",
      "('purchase_order_stage/2019-12.csv.gz', 2992, 'd000e3e35725f214e50819b595643b79', 'Sun, 1 Sep 2024 22:44:20 GMT')\n",
      "('purchase_order_stage/2019-2.csv.gz', 2384, 'ec35304584a3b329a35f3fa947d6d83e', 'Sun, 1 Sep 2024 22:44:10 GMT')\n",
      "('purchase_order_stage/2019-3.csv.gz', 2848, '05ea50ed6085b4b523e5a0bc2f7a39da', 'Sun, 1 Sep 2024 22:44:11 GMT')\n",
      "('purchase_order_stage/2019-4.csv.gz', 3088, '0f91777e275001aa673ad1318db25538', 'Sun, 1 Sep 2024 22:44:15 GMT')\n",
      "('purchase_order_stage/2019-5.csv.gz', 3200, '704e8ea3c5d51998844a5670eebe4247', 'Sun, 1 Sep 2024 22:44:16 GMT')\n",
      "('purchase_order_stage/2019-6.csv.gz', 3024, '5421c471275a12dd3f321f485fdf8cda', 'Sun, 1 Sep 2024 22:44:14 GMT')\n",
      "('purchase_order_stage/2019-7.csv.gz', 3264, '7d9d2ab10d56e64d954215e7bf310f36', 'Sun, 1 Sep 2024 22:44:13 GMT')\n",
      "('purchase_order_stage/2019-8.csv.gz', 3232, '352c02422a87bad41ea9ee7a9da19c7b', 'Sun, 1 Sep 2024 22:44:23 GMT')\n",
      "('purchase_order_stage/2019-9.csv.gz', 2992, '963a44ff53c8550ee229ef02356c00ee', 'Sun, 1 Sep 2024 22:44:23 GMT')\n",
      "('purchase_order_stage/2020-1.csv.gz', 3200, '46c9fe5687d286b1228a2cea622fbed0', 'Sun, 1 Sep 2024 22:44:15 GMT')\n",
      "('purchase_order_stage/2020-10.csv.gz', 3616, '197033d921cc2994d04be1d38cf65128', 'Sun, 1 Sep 2024 22:44:12 GMT')\n",
      "('purchase_order_stage/2020-11.csv.gz', 3376, 'e47fd7320d6fccb84b2717df2cf6051d', 'Sun, 1 Sep 2024 22:44:14 GMT')\n",
      "('purchase_order_stage/2020-12.csv.gz', 3600, '3ffcec0d72205907385e43858fba2dd2', 'Sun, 1 Sep 2024 22:44:17 GMT')\n",
      "('purchase_order_stage/2020-2.csv.gz', 2960, '9c7b909ac262c69d8d4daadc649bb372', 'Sun, 1 Sep 2024 22:44:14 GMT')\n",
      "('purchase_order_stage/2020-3.csv.gz', 2976, 'eae13afbb32d0ea797f486ce98a18554', 'Sun, 1 Sep 2024 22:44:13 GMT')\n",
      "('purchase_order_stage/2020-4.csv.gz', 3152, '6e5fc71005193ef8cce71faad09b325c', 'Sun, 1 Sep 2024 22:44:09 GMT')\n",
      "('purchase_order_stage/2020-5.csv.gz', 3280, '3d880442248b029ea12545af1b031f22', 'Sun, 1 Sep 2024 22:44:09 GMT')\n",
      "('purchase_order_stage/2020-6.csv.gz', 3312, 'c4d43f2bce65bcef0c9fd85c85609dfc', 'Sun, 1 Sep 2024 22:44:11 GMT')\n",
      "('purchase_order_stage/2020-7.csv.gz', 3568, '2ddc2be4d0c681518890818eecfd34da', 'Sun, 1 Sep 2024 22:44:11 GMT')\n",
      "('purchase_order_stage/2020-8.csv.gz', 3248, 'ab31f1c97ecb87ab4a33c9b2a82d082d', 'Sun, 1 Sep 2024 22:44:24 GMT')\n",
      "('purchase_order_stage/2020-9.csv.gz', 3392, 'd90e3f01a2e20904116a1fc5fe182dd7', 'Sun, 1 Sep 2024 22:44:24 GMT')\n",
      "('purchase_order_stage/2021-1.csv.gz', 3392, 'f0d0a6f55d01a0b491bb900548c58a8e', 'Sun, 1 Sep 2024 22:44:19 GMT')\n",
      "('purchase_order_stage/2021-10.csv.gz', 3488, '85ed5acddb4c4e259184908a47327900', 'Sun, 1 Sep 2024 22:44:22 GMT')\n",
      "('purchase_order_stage/2021-11.csv.gz', 3312, '6a243bd3988ec50af7d207eb69edf365', 'Sun, 1 Sep 2024 22:44:22 GMT')\n",
      "('purchase_order_stage/2021-12.csv.gz', 3648, '576e3274a8d1c30e220c31a1a617be6c', 'Sun, 1 Sep 2024 22:44:21 GMT')\n",
      "('purchase_order_stage/2021-2.csv.gz', 3152, '9e307383e9b6c39be3c9f2b60188887f', 'Sun, 1 Sep 2024 22:44:19 GMT')\n",
      "('purchase_order_stage/2021-3.csv.gz', 3456, 'db0a2271f35f752ad215f15376927360', 'Sun, 1 Sep 2024 22:44:19 GMT')\n",
      "('purchase_order_stage/2021-4.csv.gz', 3472, '2f22ae4663e79b810f25f98830621c95', 'Sun, 1 Sep 2024 22:44:18 GMT')\n",
      "('purchase_order_stage/2021-5.csv.gz', 3424, 'aea629e27118ca5f9b2effd2eba8e18d', 'Sun, 1 Sep 2024 22:44:18 GMT')\n",
      "('purchase_order_stage/2021-6.csv.gz', 3312, '2a52d7836118fae0bd3d795e680f29ed', 'Sun, 1 Sep 2024 22:44:17 GMT')\n",
      "('purchase_order_stage/2021-7.csv.gz', 3536, 'd7990e9a2723bda474cd927df91676d0', 'Sun, 1 Sep 2024 22:44:17 GMT')\n",
      "('purchase_order_stage/2021-8.csv.gz', 3232, '0baf1c99e12acd5454269f2821243d5d', 'Sun, 1 Sep 2024 22:44:22 GMT')\n",
      "('purchase_order_stage/2021-9.csv.gz', 3472, 'b53f384772fa72e50540cee4f25497ff', 'Sun, 1 Sep 2024 22:44:21 GMT')\n",
      "('purchase_order_stage/2022-1.csv.gz', 3744, '22a09596a6375297e653ad7fcb704b9d', 'Sun, 1 Sep 2024 22:44:13 GMT')\n",
      "('purchase_order_stage/2022-2.csv.gz', 3264, '4e5add62725238d293649fd0d6ca778d', 'Sun, 1 Sep 2024 22:44:15 GMT')\n",
      "('purchase_order_stage/2022-3.csv.gz', 3424, 'c0014eccaf2794c7d027af5dfcdabbb1', 'Sun, 1 Sep 2024 22:44:16 GMT')\n",
      "('purchase_order_stage/2022-4.csv.gz', 3408, '7d6807326b94d569f6c8e0f5e822e145', 'Sun, 1 Sep 2024 22:44:10 GMT')\n",
      "('purchase_order_stage/2022-5.csv.gz', 3456, 'c1ff4e2451808a9c2933480942993e10', 'Sun, 1 Sep 2024 22:44:12 GMT')\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "csv_directory = 'Monthlypurchaseorder/'\n",
    "\n",
    "print(f\"Looking for CSV files in: {os.path.abspath(csv_directory)}\")\n",
    "\n",
    "# Use glob to find all CSV files in the directory\n",
    "csv_files = glob.glob(os.path.join(csv_directory, \"*.csv\"))\n",
    "\n",
    "stage_name ='purchase_order_stage'\n",
    "schema_name= 'purchase_order_Schema'\n",
    "cs.execute('use schema purchase_order_Schema')\n",
    "\n",
    "for file_path in csv_files:\n",
    "    # The PUT command uploads a file to a stage\n",
    "    cs.execute(f\"PUT file://{file_path} @{schema_name}.{stage_name}\")\n",
    "\n",
    "# Confirm the files were uploaded\n",
    "cs.execute(f\"LIST @{schema_name}.{stage_name}\")\n",
    "for row in cs.fetchall():\n",
    "    print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data load completed.\n",
      "Total rows in PurchaseOrders: 8357\n",
      "Total columns in PurchaseOrders: 23\n"
     ]
    }
   ],
   "source": [
    "stage_name ='purchase_order_stage'\n",
    "schema_name= 'purchase_order_Schema'\n",
    "Table_name ='PurchaseOrders'\n",
    "\n",
    "\n",
    "copy_into_command = f\"\"\"\n",
    "COPY INTO {schema_name}.{Table_name}\n",
    "FROM @purchase_order_Schema.{stage_name}\n",
    "FILE_FORMAT = (\n",
    "TYPE = 'CSV'\n",
    "FIELD_OPTIONALLY_ENCLOSED_BY = '\"'\n",
    "SKIP_HEADER=1\n",
    "TIMESTAMP_FORMAT = 'MM/DD/YYYY HH:MI'\n",
    "DATE_FORMAT = 'MM/DD/YYYY'\n",
    "NULL_IF = ('NULL', '00:00.0', '2/29/2022', '2/28/2022 7:00:00 AM')\n",
    ")\n",
    "ON_ERROR = 'CONTINUE';\n",
    "\"\"\"\n",
    "\n",
    "# Execute the COPY INTO command and capture the output\n",
    "try:\n",
    "    cs.execute(copy_into_command)\n",
    "    print(\"Data load completed.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during COPY INTO: {e}\")\n",
    "\n",
    "# Verify the number of rows in the table\n",
    "cs.execute(f\"SELECT COUNT(*) FROM {schema_name}.{Table_name}\")\n",
    "count = cs.fetchone()[0]\n",
    "print(f\"Total rows in {Table_name}: {count}\")\n",
    "\n",
    "#verifying the columns\n",
    "\n",
    "cs.execute(f\"\"\"\n",
    "    SELECT COUNT(*)\n",
    "    FROM information_schema.columns\n",
    "    WHERE table_schema = '{schema_name.upper()}'\n",
    "    AND table_name = '{Table_name.upper()}';\n",
    "\"\"\")\n",
    "column_count = cs.fetchone()[0]\n",
    "print(f\"Total columns in {Table_name}: {column_count}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a calculated field that shows purchase order totals, i.e., for each order, sum the line item\n",
    "amounts (defined as ReceivedOuters * ExpectedUnitPricePerOuter), and name this field POAmounT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POAmount column updated with calculated values.\n",
      "Total columns in PurchaseOrders: 24\n"
     ]
    }
   ],
   "source": [
    "schema_name= 'purchase_order_Schema'\n",
    "Table_name ='PurchaseOrders'\n",
    "\n",
    "query_to_alter = f'ALTER TABLE {schema_name}.{Table_name} ADD COLUMN POAmount DECIMAL(18, 2)'\n",
    "cs.execute(query_to_alter)\n",
    "\n",
    "cs.execute(f\"\"\"\n",
    "UPDATE {schema_name}.{Table_name}\n",
    "SET POAmount = ReceivedOuters * ExpectedUnitPricePerOuter;\n",
    "\"\"\")\n",
    "print(\"POAmount column updated with calculated values.\")\n",
    "cs.execute(f\"\"\"\n",
    "    SELECT COUNT(*)\n",
    "    FROM information_schema.columns\n",
    "    WHERE table_schema = '{schema_name.upper()}'\n",
    "    AND table_name = '{Table_name.upper()}';\n",
    "\"\"\")\n",
    "column_count = cs.fetchone()[0]\n",
    "print(f\"Total columns in {Table_name}: {column_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "part 3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract and load the supplier invoice XML data\n",
    "shred the data into a table (preferably in the COPY INTO process) where each row corresponds to a single invoice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema created successfully\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# schema for the XML file  supplierTransactionXML \n",
    "schema_name2= 'SupplierTransaction_Schema'\n",
    "try:\n",
    "    cs.execute(f\"CREATE SCHEMA IF NOT EXISTS {schema_name2} \")\n",
    "    print(\"Schema created successfully\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage created successfully.\n"
     ]
    }
   ],
   "source": [
    "# creating a stage names  Xml_stage\n",
    "schema_name2= 'SupplierTransaction_Schema'\n",
    "stage_name2='Xml_stage'\n",
    "try:\n",
    "    cs.execute(f\"CREATE OR REPLACE STAGE {schema_name2}.{stage_name2}\")\n",
    "    print(\"Stage created successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PUT file://testdata/SupplierTransactionsXML.xml @SupplierTransaction_Schema.Xml_stage\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff46399e90>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#uploading the files into the stage created  using put command, i have the data file inside testdatafolder/SupplierTransactionsXML.xml\n",
    "schema_name2= 'SupplierTransaction_Schema'\n",
    "file_path = 'testdata/SupplierTransactionsXML.xml'\n",
    "stage_name2='Xml_stage'\n",
    "\n",
    "\n",
    "put_command = f\"PUT file://{file_path} @{schema_name2}.{stage_name2}\"\n",
    "print(put_command)\n",
    "# Execute the PUT command\n",
    "cs.execute(put_command)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data copied into the  staging table successfully\n"
     ]
    }
   ],
   "source": [
    "# creating a staging table in snowflakes with a variant xml_data\n",
    "\n",
    "create_table_command = \"\"\"CREATE OR REPLACE TABLE SupplierTransactions(xml_data VARIANT NOT NULL);\"\"\"\n",
    "cs.execute(create_table_command)\n",
    "\n",
    "# COPY INTO command from the copying the xml file to the staging table\n",
    "stage_name2 ='Xml_stage'\n",
    "schema_name2= 'SupplierTransaction_Schema'\n",
    "copy_into_command = f\"\"\" COPY INTO SupplierTransactions FROM @{schema_name2}.{stage_name2} FILE_FORMAT = (TYPE = 'XML') ON_ERROR='CONTINUE';\"\"\"\n",
    "\n",
    "try:\n",
    "    # Execute the COPY INTO command\n",
    "    cs.execute(copy_into_command)\n",
    "    print(\"Data copied into the  staging table successfully\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while copying data into the table: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total columns in SupplierTransactions: 15\n"
     ]
    }
   ],
   "source": [
    "\n",
    "schema_name2= 'SupplierTransaction_Schema'\n",
    "Table_name ='SupplierTransactions'\n",
    "\n",
    "cs.execute(f\"\"\"\n",
    "CREATE OR REPLACE TABLE {schema_name2}.{Table_name} AS\n",
    "SELECT\n",
    "    XMLGET( r.value, 'SupplierTransactionID' ):\"$\"::INTEGER AS SupplierTransactionID,\n",
    "    XMLGET( r.value, 'SupplierID' ):\"$\"::INTEGER AS SupplierID,\n",
    "    XMLGET( r.value, 'TransactionTypeID' ):\"$\"::INTEGER AS TransactionTypeID,\n",
    "    CASE WHEN REGEXP_LIKE(XMLGET(r.value, 'PurchaseOrderID'):\"$\", '^[0-9]+$') THEN TO_NUMBER(XMLGET(r.value, 'PurchaseOrderID'):\"$\") ELSE NULL END AS PurchaseOrderID,\n",
    "    XMLGET( r.value, 'PaymentMethodID' ):\"$\"::INTEGER AS PaymentMethodID,\n",
    "    CASE WHEN REGEXP_LIKE(XMLGET(r.value, 'SupplierInvoiceNumber'):\"$\", '^[0-9]+$') THEN TO_NUMBER(XMLGET(r.value, 'SupplierInvoiceNumber'):\"$\") ELSE NULL END AS SupplierInvoiceNumber,\n",
    "    XMLGET( r.value, 'TransactionDate' ):\"$\"::STRING AS TransactionDate,\n",
    "    XMLGET( r.value, 'AmountExcludingTax' ):\"$\"::FLOAT AS AmountExcludingTax,\n",
    "    XMLGET( r.value, 'TaxAmount' ):\"$\"::FLOAT AS TaxAmount,\n",
    "    XMLGET( r.value, 'TransactionAmount' ):\"$\"::FLOAT AS TransactionAmount,\n",
    "    XMLGET( r.value, 'OutstandingBalance' ):\"$\"::FLOAT AS OutstandingBalance,\n",
    "    XMLGET( r.value, 'FinalizationDate' ):\"$\"::STRING AS FinalizationDate,\n",
    "    XMLGET( r.value, 'IsFinalized' ):\"$\"::INTEGER AS IsFinalized,\n",
    "    XMLGET( r.value, 'LastEditedBy' ):\"$\"::INTEGER AS LastEditedBy,\n",
    "    XMLGET( r.value, 'LastEditedWhen' ):\"$\"::STRING AS LastEditedWhen\n",
    "FROM SupplierTransactions,  \n",
    "LATERAL FLATTEN(SupplierTransactions.xml_data:\"$\") r\n",
    "WHERE GET( r.value, '@') = 'row' \"\"\")\n",
    "#verifying the columns\n",
    "cs.execute(f\"\"\"\n",
    "    SELECT COUNT(*)\n",
    "    FROM information_schema.columns\n",
    "    WHERE table_schema = '{schema_name2.upper()}'\n",
    "    AND table_name = '{Table_name.upper()}';\n",
    "\"\"\")\n",
    "column_count = cs.fetchone()[0]\n",
    "print(f\"Total columns in {Table_name}: {column_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join the purchases data from step 2 and the supplier invoices data from step 3 (only include\n",
    "matching rows);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff46399e90>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "command = \"\"\"\n",
    "CREATE OR REPLACE TABLE PurchaseOrderSupplierTransaction AS\n",
    "SELECT a.PurchaseOrderID, \n",
    "a.SupplierID, a. OrderDate, a.ExpectedDeliveryDate, a.PurchaseOrderLineID, a.StockItemID, \n",
    "a.OrderedOuters, a.ReceivedOuters, a.ExpectedUnitPricePerOuter , a.LastReceiptDate, a.POAmount, b.SupplierTransactionID, b.SupplierInvoiceNumber, \n",
    "b.TransactionDate, b.AmountExcludingTax, b.TaxAmount, b.TransactionAmount, b.FinalizationDate\n",
    "FROM purchase_order_Schema.PurchaseOrders a\n",
    "JOIN SupplierTransaction_Schema.SupplierTransactions b \n",
    "using (SupplierID,PurchaseOrderID)\n",
    "\"\"\"\n",
    "cs.execute(command)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the joined data from step 4, create a calculated field that shows the difference between\n",
    "AmountExcludingTax and POAmount, name this field invoiced_vs_quoted, and save the result as a\n",
    "materialized view named purchase_orders_and_invoices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff46399e90>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_to_create_view = \"\"\"\n",
    "CREATE OR REPLACE MATERIALIZED VIEW PURCHASE_ORDERS_AND_INVOICES AS (\n",
    "SELECT AmountExcludingTax, POAmount, (AmountExcludingTax - POAmount) AS invoiced_vs_quoted\n",
    "FROM PurchaseOrderSupplierTransaction\n",
    ")\n",
    "\"\"\"\n",
    "cs.execute(query_to_create_view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1627734.0, Decimal('153300.00'), 1474434.0), (1624638.0, Decimal('153048.00'), 1471590.0), (1619580.0, Decimal('152376.00'), 1467204.0), (1618188.0, Decimal('152208.00'), 1465980.0), (1618332.0, Decimal('152544.00'), 1465788.0), (1616604.0, Decimal('152544.00'), 1464060.0), (1616370.0, Decimal('152880.00'), 1463490.0), (1627734.0, Decimal('164790.00'), 1462944.0), (1613106.0, Decimal('150780.00'), 1462326.0), (1624638.0, Decimal('164430.00'), 1460208.0)]\n",
      "[(1627734.0, Decimal('153300.00'), 1474434.0), (1624638.0, Decimal('153048.00'), 1471590.0), (1619580.0, Decimal('152376.00'), 1467204.0), (1618188.0, Decimal('152208.00'), 1465980.0), (1618332.0, Decimal('152544.00'), 1465788.0), (1616604.0, Decimal('152544.00'), 1464060.0), (1616370.0, Decimal('152880.00'), 1463490.0), (1627734.0, Decimal('164790.00'), 1462944.0), (1613106.0, Decimal('150780.00'), 1462326.0), (1624638.0, Decimal('164430.00'), 1460208.0)]\n",
      "[(1627734.0, Decimal('153300.00'), 1474434.0), (1624638.0, Decimal('153048.00'), 1471590.0), (1619580.0, Decimal('152376.00'), 1467204.0), (1618188.0, Decimal('152208.00'), 1465980.0), (1618332.0, Decimal('152544.00'), 1465788.0), (1616604.0, Decimal('152544.00'), 1464060.0), (1616370.0, Decimal('152880.00'), 1463490.0), (1627734.0, Decimal('164790.00'), 1462944.0), (1613106.0, Decimal('150780.00'), 1462326.0), (1624638.0, Decimal('164430.00'), 1460208.0)]\n",
      "[(1627734.0, Decimal('153300.00'), 1474434.0), (1624638.0, Decimal('153048.00'), 1471590.0), (1619580.0, Decimal('152376.00'), 1467204.0), (1618188.0, Decimal('152208.00'), 1465980.0), (1618332.0, Decimal('152544.00'), 1465788.0), (1616604.0, Decimal('152544.00'), 1464060.0), (1616370.0, Decimal('152880.00'), 1463490.0), (1627734.0, Decimal('164790.00'), 1462944.0), (1613106.0, Decimal('150780.00'), 1462326.0), (1624638.0, Decimal('164430.00'), 1460208.0)]\n",
      "[(1627734.0, Decimal('153300.00'), 1474434.0), (1624638.0, Decimal('153048.00'), 1471590.0), (1619580.0, Decimal('152376.00'), 1467204.0), (1618188.0, Decimal('152208.00'), 1465980.0), (1618332.0, Decimal('152544.00'), 1465788.0), (1616604.0, Decimal('152544.00'), 1464060.0), (1616370.0, Decimal('152880.00'), 1463490.0), (1627734.0, Decimal('164790.00'), 1462944.0), (1613106.0, Decimal('150780.00'), 1462326.0), (1624638.0, Decimal('164430.00'), 1460208.0)]\n",
      "[(1627734.0, Decimal('153300.00'), 1474434.0), (1624638.0, Decimal('153048.00'), 1471590.0), (1619580.0, Decimal('152376.00'), 1467204.0), (1618188.0, Decimal('152208.00'), 1465980.0), (1618332.0, Decimal('152544.00'), 1465788.0), (1616604.0, Decimal('152544.00'), 1464060.0), (1616370.0, Decimal('152880.00'), 1463490.0), (1627734.0, Decimal('164790.00'), 1462944.0), (1613106.0, Decimal('150780.00'), 1462326.0), (1624638.0, Decimal('164430.00'), 1460208.0)]\n",
      "[(1627734.0, Decimal('153300.00'), 1474434.0), (1624638.0, Decimal('153048.00'), 1471590.0), (1619580.0, Decimal('152376.00'), 1467204.0), (1618188.0, Decimal('152208.00'), 1465980.0), (1618332.0, Decimal('152544.00'), 1465788.0), (1616604.0, Decimal('152544.00'), 1464060.0), (1616370.0, Decimal('152880.00'), 1463490.0), (1627734.0, Decimal('164790.00'), 1462944.0), (1613106.0, Decimal('150780.00'), 1462326.0), (1624638.0, Decimal('164430.00'), 1460208.0)]\n",
      "[(1627734.0, Decimal('153300.00'), 1474434.0), (1624638.0, Decimal('153048.00'), 1471590.0), (1619580.0, Decimal('152376.00'), 1467204.0), (1618188.0, Decimal('152208.00'), 1465980.0), (1618332.0, Decimal('152544.00'), 1465788.0), (1616604.0, Decimal('152544.00'), 1464060.0), (1616370.0, Decimal('152880.00'), 1463490.0), (1627734.0, Decimal('164790.00'), 1462944.0), (1613106.0, Decimal('150780.00'), 1462326.0), (1624638.0, Decimal('164430.00'), 1460208.0)]\n",
      "[(1627734.0, Decimal('153300.00'), 1474434.0), (1624638.0, Decimal('153048.00'), 1471590.0), (1619580.0, Decimal('152376.00'), 1467204.0), (1618188.0, Decimal('152208.00'), 1465980.0), (1618332.0, Decimal('152544.00'), 1465788.0), (1616604.0, Decimal('152544.00'), 1464060.0), (1616370.0, Decimal('152880.00'), 1463490.0), (1627734.0, Decimal('164790.00'), 1462944.0), (1613106.0, Decimal('150780.00'), 1462326.0), (1624638.0, Decimal('164430.00'), 1460208.0)]\n",
      "[(1627734.0, Decimal('153300.00'), 1474434.0), (1624638.0, Decimal('153048.00'), 1471590.0), (1619580.0, Decimal('152376.00'), 1467204.0), (1618188.0, Decimal('152208.00'), 1465980.0), (1618332.0, Decimal('152544.00'), 1465788.0), (1616604.0, Decimal('152544.00'), 1464060.0), (1616370.0, Decimal('152880.00'), 1463490.0), (1627734.0, Decimal('164790.00'), 1462944.0), (1613106.0, Decimal('150780.00'), 1462326.0), (1624638.0, Decimal('164430.00'), 1460208.0)]\n"
     ]
    }
   ],
   "source": [
    "cs.execute(\"select * from PURCHASE_ORDERS_AND_INVOICES order by invoiced_vs_quoted desc limit 10\")\n",
    "rows = cs.fetchmany(10)\n",
    "for row in rows:\n",
    "    print(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PART 6 \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Extract the supplier_case data from postgres, do not import the data into Python, instead use\n",
    "Python to move the data from postgres to your local drive and then directly into a Snowflake stage\n",
    "a. Consider creating a Python function that can take a csv file path as input and then generate field\n",
    "definitions (field names and datatypes based on the header and data types in the file) that can\n",
    "then be used in CREATE TABLE statement.\n",
    "b. You need to use psycopg2 or a similar Python library to connect to the postgres database within\n",
    "Python, issue a command to postgres to have postgres save the supplier_case data to file, and\n",
    "then use cs.execute to move the file to an internal Snowflake stage and eventually into a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff46399e90>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#specifying the Database , Schema for supplier data, Stage \n",
    "Database_name = 'Group_26_DataBase'\n",
    "cs.execute(f\"use DATABASE {Database_name}\") \n",
    "\n",
    "stage_name3 = \"Supplier\"\n",
    "schema_name3= 'Supplier_schema'\n",
    "\n",
    "cs.execute(f\"CREATE SCHEMA IF NOT EXISTS {schema_name3} \")\n",
    "cs.execute(f\"CREATE OR REPLACE STAGE {schema_name3}.{stage_name3} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully exported to /home/jovyan/Desktop/testrepo/supplier_case.csv\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import os\n",
    "\n",
    "def export_data_to_csv(postgres_conn_details, query, output_csv_path):\n",
    "    \"\"\"\n",
    "    Export data from a PostgreSQL database to a CSV file \n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Connect to PostgreSQL\n",
    "        conn = psycopg2.connect(**postgres_conn_details)\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        # Write the data to a CSV file using COPY TO STDOUT\n",
    "        with open(output_csv_path, 'w') as csvfile:\n",
    "            cursor.copy_expert(query, csvfile)\n",
    "\n",
    "        print(f\"Data successfully exported to {output_csv_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Define PostgreSQL connection details\n",
    "postgres_conn_details = {\n",
    "    'dbname': 'WestCoastImporters',   \n",
    "    'user': 'jovyan',   \n",
    "    'password': 'postgres',   \n",
    "    'host': '127.0.0.1',  \n",
    "    'port': 8765 \n",
    "}\n",
    "\n",
    "# Define the SQL COPY query\n",
    "query = \"COPY (SELECT * FROM supplier_case) TO STDOUT WITH CSV HEADER\"\n",
    "\n",
    "# Get the current working directory\n",
    "directory = os.getcwd()\n",
    "\n",
    "# Check if the directory exists, if not, create it\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "csv_file_path = os.path.join(directory, 'supplier_case.csv')\n",
    "\n",
    "# function call\n",
    "export_data_to_csv(postgres_conn_details, query, csv_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/Desktop/testrepo/supplier_case.csv\n",
      "File /home/jovyan/Desktop/testrepo/supplier_case.csv successfully uploaded to Snowflake stage @Supplier.\n"
     ]
    }
   ],
   "source": [
    "# load the csv in to the stage\n",
    "\n",
    "stage_name3 = \"Supplier\"\n",
    "schema_name3= 'Supplier_schema'\n",
    "try:\n",
    "\n",
    "    csv_file = os.getcwd()+'/supplier_case.csv'\n",
    "    print(csv_file)\n",
    "    cs.execute(f\"PUT file://{csv_file} @{schema_name3}.{stage_name3}\")\n",
    "    print(f\"File {csv_file} successfully uploaded to Snowflake stage @{stage_name3}.\")\n",
    "\n",
    "except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff46399e90>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "command = \"\"\"\n",
    "CREATE OR REPLACE FILE FORMAT SUPPLIER_CASE \n",
    "    TYPE = CSV\n",
    "    FIELD_OPTIONALLY_ENCLOSED_BY = '\"'\n",
    "    PARSE_HEADER = TRUE\n",
    "    TIMESTAMP_FORMAT = 'MM/DD/YYYY HH24:MI'\n",
    "\"\"\"\n",
    "cs.execute(command)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff46399e90>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sql_table=\"\"\"\n",
    "    CREATE OR REPLACE TABLE Supplier_schema.supplierCase (\n",
    "        SupplierID INTEGER,\n",
    "        SupplierName STRING,\n",
    "        SupplierCategoryID INTEGER,\n",
    "        PrimaryContactPersonID INTEGER,\n",
    "        alternatecontactpersonid INTEGER,\n",
    "        DeliveryMethodID INTEGER,\n",
    "        PostalCityID INTEGER,\n",
    "        SupplierReference STRING,\n",
    "        BankAccountName STRING,\n",
    "        BankAccountBranch STRING,\n",
    "        BankAccountCode INTEGER,\n",
    "        BankAccountNumber INTEGER,\n",
    "        BankInternationalCode INTEGER,\n",
    "        PaymentDays INTEGER,\n",
    "        InternalComments STRING,\n",
    "        PhoneNumber STRING,\n",
    "        FaxNumber STRING,\n",
    "        WebsiteURL STRING,\n",
    "        DeliveryAddressLine1 STRING,\n",
    "        DeliveryAddressLine2 STRING,\n",
    "        DeliveryPostalCode STRING,\n",
    "        DeliveryLocation STRING,\n",
    "        PostalAddressLine1 STRING,\n",
    "        PostalAddressLine2 STRING,\n",
    "        PostalPostalCode INTEGER,\n",
    "        Lasteditedby INTEGER,\n",
    "        ValidFrom STRING,\n",
    "        ValidTo STRING\n",
    "    );\n",
    "\"\"\"\n",
    "cs.execute(sql_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('supplier/supplier_case.csv.gz', 1968, '007238f66fde17b20daf6a014ac70416', 'Sun, 1 Sep 2024 22:44:35 GMT')\n"
     ]
    }
   ],
   "source": [
    "#Check what is csv name inside snowflake stage\n",
    "cs.execute(f\"LIST @{schema_name3}.{stage_name3};\")\n",
    "staged_files = cs.fetchall()\n",
    "for file in staged_files:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('supplier/supplier_case.csv.gz', 'LOADED', 13, 13, 13, 0, None, None, None, None)\n"
     ]
    }
   ],
   "source": [
    "stage_name3 = \"Supplier\"\n",
    "schema_name3= 'Supplier_schema'\n",
    "cs.execute(\n",
    "    \"\"\"\n",
    "    COPY INTO Supplier_schema.supplierCase\n",
    "    FROM @Supplier_schema.Supplier\n",
    "    FILE_FORMAT = SUPPLIER_CASE\n",
    "    MATCH_BY_COLUMN_NAME = CASE_INSENSITIVE\n",
    "    ON_ERROR = 'CONTINUE' \n",
    "    \"\"\"\n",
    ")\n",
    "# Fetch and display any output or errors\n",
    "load_results = cs.fetchall()\n",
    "for result in load_results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 7 a\n",
    "While the weather station data contain zip codes, we will pretend that this table does not have this information and instead use latitude and longitude information to determine which weather station to use for each zip code. The approach used in\n",
    "https://towardsdatascience.com/noaa-weather-data-in-snowflake-free-20e90ee916ed \n",
    "can be helpful for (note that this is based on a different data set, but the idea of using latitude and longitude is the same) \n",
    "finding weather stations closest to each zip code (only use one weather station per zip code). \n",
    "For this to work you need to find a data file with zip code – geo location mappings, e.g., from the US census (the\n",
    "data zip folder on Canvas contains a ZCTA file with this information; in this file GEOID is the five\n",
    "digit ZIP Code, INTPTLAT is Latitude, and INTPTLONG is Longitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff46399e90>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#specifying the Database , Schema for supplier data, Stage \n",
    "Database_name = 'Group_26_DataBase'\n",
    "cs.execute(f\"use DATABASE {Database_name}\") \n",
    "\n",
    "stage_name4 = \"weather_stage\"\n",
    "schema_name4= 'weather_schema'\n",
    "\n",
    "cs.execute(f\"CREATE SCHEMA IF NOT EXISTS {schema_name4} \")\n",
    "cs.execute(f\"CREATE OR REPLACE STAGE {schema_name4}.{stage_name4} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/Desktop/testrepo/testdata/2021_Gaz_zcta_national.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff46399e90>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting the data from the local and uploading it to the stage\n",
    "\n",
    "import os\n",
    "file = os.getcwd() + \"/testdata/2021_Gaz_zcta_national.txt\"\n",
    "stage_name4 = \"weather_stage\"\n",
    "schema_name4= 'weather_schema' \n",
    "print(file)\n",
    "cs.execute(f\"PUT file://{file} @weather_schema.weather_stage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff46399e90>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a table name zcta_table\n",
    "cs.execute(\"\"\"CREATE OR REPLACE TABLE zcta_table (\n",
    "    GEOID VARCHAR(5),\n",
    "    ALAND NUMERIC,\n",
    "    AWATER NUMERIC,\n",
    "    ALAND_SQMI FLOAT,\n",
    "    AWATER_SQMI FLOAT,\n",
    "    INTPTLAT FLOAT,\n",
    "    INTPTLONG FLOAT\n",
    ");\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff46399e90>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# copy data in to the table from the stage\n",
    "cs.execute(\"\"\"\n",
    "COPY INTO zcta_table\n",
    "FROM @weather_schema.weather_stage\n",
    "FILE_FORMAT = (\n",
    "    TYPE = 'CSV',\n",
    "    FIELD_OPTIONALLY_ENCLOSED_BY = '\"',\n",
    "    FIELD_DELIMITER = '\\t',\n",
    "    SKIP_HEADER = 1\n",
    ")\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff46399e90>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# joining two tables and creating a table with  required columns\n",
    "cs.execute(\"\"\"\n",
    "        CREATE OR REPLACE TABLE supplier_zip_geolocation AS (\n",
    "        SELECT sc.PostalPostalCode, z.INTPTLAT AS latitude, z.INTPTLONG AS longitude\n",
    "        FROM Supplier_schema.supplierCase sc\n",
    "        JOIN zcta_table z ON sc.postalpostalcode = z.GEOID\n",
    "        GROUP BY sc.PostalPostalCode, z.INTPTLAT, z.INTPTLONG);\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff46399e90>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the Table zip_weather_station_mapping \n",
    "# by cross joining the supplier_zip_geolocation,JOIN WEATHER__ENVIRONMENT.cybersyn.noaa_weather_station_index \n",
    "\n",
    "cs.execute(\"\"\"\n",
    "CREATE OR REPLACE TABLE zip_weather_station_mapping AS\n",
    "    SELECT \n",
    "        sz.PostalPostalCode,\n",
    "        ws.noaa_weather_station_id AS station_id,\n",
    "        ws.noaa_weather_station_name AS station_name,\n",
    "        SQRT(\n",
    "            POW(69.1 * (sz.latitude - ws.latitude), 2) +\n",
    "            POW(69.1 * (ws.longitude - sz.longitude) * COS(sz.latitude / 57.3), 2)\n",
    "        ) AS distance\n",
    "    FROM supplier_zip_geolocation sz\n",
    "    CROSS JOIN WEATHER__ENVIRONMENT.cybersyn.noaa_weather_station_index ws\n",
    "    QUALIFY ROW_NUMBER() OVER (PARTITION BY sz.postalpostalcode ORDER BY distance ASC) = 1;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff46399e90>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a table zip_weather_station_mapping_temp \n",
    "cs.execute(\"\"\"\n",
    "CREATE OR REPLACE TABLE zip_weather_station_mapping_temp AS\n",
    "    SELECT \n",
    "        sz.postalpostalcode,\n",
    "        ws.noaa_weather_station_id AS station_id,\n",
    "        ws.noaa_weather_station_name AS station_name,\n",
    "        st_distance(\n",
    "            st_makepoint(sz.longitude, sz.latitude),\n",
    "            st_makepoint(ws.longitude, ws.latitude)\n",
    "        ) AS distance\n",
    "    FROM supplier_zip_geolocation sz\n",
    "    JOIN WEATHER__ENVIRONMENT.cybersyn.noaa_weather_station_index ws\n",
    "    ON st_distance(st_makepoint(sz.longitude, sz.latitude), st_makepoint(ws.longitude, ws.latitude)) < 50000\n",
    "    QUALIFY ROW_NUMBER() OVER (PARTITION BY sz.postalpostalcode ORDER BY distance ASC) = 1;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 7 b Create a materialized view named supplier_zip_code_weather that contains the unique zip codes (PostalPostalCode) from the supplier data, date, and daily high temperatures, i.e., the view should have three columns (zip code, date, and high temperature) and one row per day and unique supplier zip code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff46399e90>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs.execute(\"\"\"\n",
    "CREATE OR REPLACE TABLE zip_code_weather_data AS\n",
    "           SELECT \n",
    "            z.postalpostalcode,\n",
    "            wm.date,\n",
    "            wm.value as Max_Temp,\n",
    "            wm.variable\n",
    "            FROM zip_weather_station_mapping z\n",
    "            JOIN WEATHER__ENVIRONMENT.cybersyn.noaa_weather_metrics_timeseries wm\n",
    "            ON z.station_id = wm.noaa_weather_station_id\n",
    "            WHERE wm.variable = 'maximum_temperature';\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff46399e90>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs.execute(\"\"\"\n",
    "CREATE OR REPLACE TABLE zip_code_weather_data_temp AS\n",
    "           SELECT \n",
    "            z.postalpostalcode,\n",
    "            wm.date,\n",
    "            wm.value as Max_Temp,\n",
    "            wm.variable\n",
    "            FROM zip_weather_station_mapping_temp z\n",
    "            JOIN WEATHER__ENVIRONMENT.cybersyn.noaa_weather_metrics_timeseries wm\n",
    "            ON z.station_id = wm.noaa_weather_station_id\n",
    "            WHERE wm.variable = 'maximum_temperature';\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff46399e90>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs.execute(\"\"\"\n",
    "CREATE OR REPLACE TABLE supplier_zip_code_weather_temp AS \n",
    "SELECT A.PostalPostalCode, B.date, B.Max_temp \n",
    "        FROM Supplier_schema.supplierCase as A\n",
    "        LEFT JOIN zip_code_weather_data as B ON A.postalpostalcode = B.postalpostalcode\n",
    "        ORDER BY DATE;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0xffff46399e90>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a materialized view \n",
    "\n",
    "command = \"\"\"CREATE OR REPLACE MATERIALIZED VIEW supplier_zip_code_weather AS \n",
    "            (SELECT * FROM supplier_zip_code_weather_temp);\"\"\"\n",
    "cs.execute(command)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PART 8 \n",
    "\n",
    "Join purchase_orders_and_invoices, supplier_case, and supplier_zip_code_weather based on zip\n",
    "codes and the transaction date. Only include transactions that have matching temperature readings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cs.execute(\"\"\"CREATE OR REPLACE VIEW order_zip_temp AS \n",
    "SELECT A.*\n",
    "FROM supplier_zip_code_weather A\n",
    "LEFT JOIN SupplierTransaction_Schema.PurchaseOrderSupplierTransaction B \n",
    "ON A.DATE = B.TRANSACTIONDATE\n",
    "LEFT JOIN Supplier_schema.supplierCase C \n",
    "ON A.postalpostalcode = C.postalpostalcode\n",
    "WHERE A.max_temp IS NOT NULL;\"\"\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
